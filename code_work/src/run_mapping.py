"""
ë¬¸í•­-ì´ë¯¸ì§€ ë§¤í•‘ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
ìš´ì „ë©´í—ˆ ì‹œí—˜ PDFì—ì„œ ë¬¸í•­ë²ˆí˜¸ì™€ ì´ë¯¸ì§€ë¥¼ ìë™ìœ¼ë¡œ ì—°ê²°í•©ë‹ˆë‹¤.
"""

import sys
from pathlib import Path
from typing import Dict

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(str(Path(__file__).parent))

from pdf_image_extractor import (
    extract_questions_and_images_from_pdf,
    process_license_exam_pdfs,
    save_mapping_to_json,
    load_mapping_from_json
)
from mapping_validator import (
    validate_mapping_results,
    generate_mapping_report,
    main_mapping_workflow,
    export_mapping_to_dataframe
)
import pandas as pd


def setup_environment():
    """
    í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.
    """
    required_packages = [
        'PyMuPDF',  # fitz
        'opencv-python',  # cv2
        'pillow',  # PIL
        'pandas',
        'matplotlib',
        'numpy'
    ]
    
    print("í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘...")
    for package in required_packages:
        try:
            __import__(package.replace('-', '_').split('_')[0])
            print(f"âœ… {package} - ì´ë¯¸ ì„¤ì¹˜ë¨")
        except ImportError:
            print(f"âŒ {package} - ì„¤ì¹˜ í•„ìš”")
            print(f"   pip install {package}")


def run_single_pdf_processing(pdf_path: str) -> pd.DataFrame:
    """
    ë‹¨ì¼ PDF íŒŒì¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    
    Args:
        pdf_path: PDF íŒŒì¼ ê²½ë¡œ
        
    Returns:
        pd.DataFrame: ë§¤í•‘ ê²°ê³¼ ë°ì´í„°í”„ë ˆì„
    """
    
    print(f"\n{'='*60}")
    print(f"ğŸ“ ì²˜ë¦¬ ëŒ€ìƒ: {Path(pdf_path).name}")
    print(f"{'='*60}")
    
    if not Path(pdf_path).exists():
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")
        return pd.DataFrame()
    
    try:
        # ì „ì²´ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        result_df = main_mapping_workflow(pdf_path)
        
        print(f"\nğŸ“‹ ì²˜ë¦¬ ê²°ê³¼:")
        print(f"   ì´ ë§¤í•‘ ìˆ˜: {len(result_df)}")
        print(f"   ì´ë¯¸ì§€ê°€ ìˆëŠ” ë¬¸í•­: {result_df['has_image'].sum()}")
        
        return result_df
        
    except Exception as e:
        print(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()
        return pd.DataFrame()


def run_batch_processing(data_dir: str = "../../data") -> Dict[str, pd.DataFrame]:
    """
    ì—¬ëŸ¬ PDF íŒŒì¼ì„ ì¼ê´„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    
    Args:
        data_dir: ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ
        
    Returns:
        Dict[str, pd.DataFrame]: íŒŒì¼ë³„ ì²˜ë¦¬ ê²°ê³¼
    """
    
    pdf_files = [
        "2_raw_data_fromkoroad_ì•ˆì „í‘œì§€.pdf",
        "3_raw_data_fromkoroad_ì‚¬ì§„í˜•.pdf", 
        "4_raw_data_fromkoroad_ì¼ëŸ¬ìŠ¤íŠ¸.pdf"
    ]
    
    all_results = {}
    
    print(f"\nğŸš€ ì¼ê´„ ì²˜ë¦¬ ì‹œì‘ (ì´ {len(pdf_files)}ê°œ íŒŒì¼)")
    print(f"ë°ì´í„° ë””ë ‰í† ë¦¬: {Path(data_dir).absolute()}")
    
    for i, pdf_file in enumerate(pdf_files, 1):
        pdf_path = Path(data_dir) / pdf_file
        
        print(f"\n[{i}/{len(pdf_files)}] {pdf_file}")
        
        if pdf_path.exists():
            result_df = run_single_pdf_processing(str(pdf_path))
            if not result_df.empty:
                file_key = pdf_file.replace('.pdf', '').split('_')[-1]
                all_results[file_key] = result_df
        else:
            print(f"âš ï¸  íŒŒì¼ ê±´ë„ˆëœ€ (ì¡´ì¬í•˜ì§€ ì•ŠìŒ): {pdf_file}")
    
    # í†µí•© ê²°ê³¼ ì €ì¥
    if all_results:
        print(f"\nğŸ“Š ì „ì²´ ê²°ê³¼ ìš”ì•½:")
        total_mappings = 0
        for file_type, df in all_results.items():
            mappings = len(df)
            total_mappings += mappings
            print(f"   {file_type}: {mappings}ê°œ ë§¤í•‘")
        
        print(f"   ì „ì²´: {total_mappings}ê°œ ë§¤í•‘")
        
        # í†µí•© ë°ì´í„°í”„ë ˆì„ ìƒì„±
        combined_df = pd.DataFrame()
        for file_type, df in all_results.items():
            df_copy = df.copy()
            df_copy['source_file'] = file_type
            combined_df = pd.concat([combined_df, df_copy], ignore_index=True)
        
        # í†µí•© ê²°ê³¼ë¥¼ data/results/ ë””ë ‰í† ë¦¬ì— ì €ì¥
        base_data_dir = Path(data_dir).absolute()
        results_dir = base_data_dir / "results"
        results_dir.mkdir(parents=True, exist_ok=True)
        
        combined_path = results_dir / "all_question_image_mappings.csv"
        combined_df.to_csv(combined_path, index=False, encoding='utf-8-sig')
        print(f"   í†µí•© íŒŒì¼ ì €ì¥: {combined_path}")
    
    return all_results


def validate_and_fix_mappings(mapping_json_path: str) -> Dict:
    """
    ì €ì¥ëœ ë§¤í•‘ ê²°ê³¼ë¥¼ ê²€ì¦í•˜ê³  ìˆ˜ì •í•©ë‹ˆë‹¤.
    
    Args:
        mapping_json_path: ë§¤í•‘ JSON íŒŒì¼ ê²½ë¡œ
        
    Returns:
        Dict: ìˆ˜ì •ëœ ë§¤í•‘ ê²°ê³¼
    """
    
    print(f"\nğŸ” ë§¤í•‘ ê²€ì¦: {mapping_json_path}")
    
    if not Path(mapping_json_path).exists():
        print(f"âŒ ë§¤í•‘ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {mapping_json_path}")
        return {}
    
    # ë§¤í•‘ ë¡œë“œ
    mapping_result = load_mapping_from_json(mapping_json_path)
    
    # ê²€ì¦
    validation_df = validate_mapping_results(mapping_result)
    print("\nğŸ“‹ ê²€ì¦ ê²°ê³¼:")
    print(validation_df[['page_number', 'question_count', 'mapped_count', 'status']].to_string(index=False))
    
    # ë¬¸ì œê°€ ìˆëŠ” í˜ì´ì§€ í™•ì¸
    problem_pages = validation_df[validation_df['status'] != 'Good']
    if not problem_pages.empty:
        print(f"\nâš ï¸  ë¬¸ì œê°€ ìˆëŠ” í˜ì´ì§€: {len(problem_pages)}ê°œ")
        for _, row in problem_pages.iterrows():
            print(f"   Page {row['page_number']}: {row['status']} (ë¬¸í•­:{row['question_count']}, ë§¤í•‘:{row['mapped_count']})")
    
    return mapping_result


def create_quick_preview(mapping_result: Dict, max_items: int = 10) -> None:
    """
    ë§¤í•‘ ê²°ê³¼ì˜ ë¹ ë¥¸ ë¯¸ë¦¬ë³´ê¸°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        mapping_result: ë§¤í•‘ ê²°ê³¼
        max_items: í‘œì‹œí•  ìµœëŒ€ í•­ëª© ìˆ˜
    """
    
    print(f"\nğŸ‘€ ë§¤í•‘ ë¯¸ë¦¬ë³´ê¸° (ìµœëŒ€ {max_items}ê°œ):")
    print("-" * 80)
    
    mapping = mapping_result['question_image_mapping']
    
    for i, (question_id, image_path) in enumerate(list(mapping.items())[:max_items]):
        image_name = Path(image_path).name
        exists = "âœ…" if Path(image_path).exists() else "âŒ"
        print(f"{i+1:2d}. {question_id:15s} â†’ {image_name:30s} {exists}")
    
    total_count = len(mapping)
    if total_count > max_items:
        print(f"    ... ë° {total_count - max_items}ê°œ ë”")
    
    print("-" * 80)


def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
    """
    
    print("ğŸ¯ ìš´ì „ë©´í—ˆ ì‹œí—˜ ë¬¸í•­-ì´ë¯¸ì§€ ë§¤í•‘ ë„êµ¬")
    print("=" * 60)
    
    # í™˜ê²½ ì„¤ì • í™•ì¸
    setup_environment()
    
    # ë°ì´í„° ë””ë ‰í† ë¦¬ í™•ì¸
    data_dir = "../../data"
    if not Path(data_dir).exists():
        print(f"âŒ ë°ì´í„° ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {Path(data_dir).absolute()}")
        print("ìƒëŒ€ ê²½ë¡œë¥¼ ì¡°ì •í•˜ê±°ë‚˜ ì˜¬ë°”ë¥¸ ê²½ë¡œë¥¼ ì§€ì •í•´ì£¼ì„¸ìš”.")
        return
    
    print(f"ğŸ“‚ ë°ì´í„° ë””ë ‰í† ë¦¬: {Path(data_dir).absolute()}")
    
    # ì‚¬ìš©ì ì„ íƒ
    print("\nì‹¤í–‰í•  ì‘ì—…ì„ ì„ íƒí•˜ì„¸ìš”:")
    print("1. ë‹¨ì¼ PDF íŒŒì¼ ì²˜ë¦¬")
    print("2. ì „ì²´ PDF íŒŒì¼ ì¼ê´„ ì²˜ë¦¬")
    print("3. ê¸°ì¡´ ë§¤í•‘ ê²°ê³¼ ê²€ì¦")
    print("4. ì¢…ë£Œ")
    
    choice = input("\nì„ íƒ (1-4): ").strip()
    
    if choice == "1":
        # ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬
        print("\nì‚¬ìš© ê°€ëŠ¥í•œ PDF íŒŒì¼:")
        pdf_files = list(Path(data_dir).glob("*raw_data_fromkoroad*.pdf"))
        for i, pdf_file in enumerate(pdf_files, 1):
            print(f"  {i}. {pdf_file.name}")
        
        if not pdf_files:
            print("âŒ PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        file_choice = input(f"\níŒŒì¼ ì„ íƒ (1-{len(pdf_files)}): ").strip()
        try:
            file_index = int(file_choice) - 1
            if 0 <= file_index < len(pdf_files):
                run_single_pdf_processing(str(pdf_files[file_index]))
            else:
                print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")
        except ValueError:
            print("âŒ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    elif choice == "2":
        # ì¼ê´„ ì²˜ë¦¬
        run_batch_processing(data_dir)
    
    elif choice == "3":
        # ê¸°ì¡´ ë§¤í•‘ ê²€ì¦
        data_dir_path = Path(data_dir).absolute()
        results_dir = data_dir_path / "results"
        
        # results ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  í•˜ìœ„ í´ë”ì—ì„œ JSON íŒŒì¼ ì°¾ê¸°
        json_files = list(results_dir.rglob("mapping_results_*.json")) if results_dir.exists() else []
        
        if not json_files:
            print("âŒ ë§¤í•‘ ê²°ê³¼ íŒŒì¼(mapping_results_*.json)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print(f"   ê²€ìƒ‰ ê²½ë¡œ: {results_dir}")
            return
        
        print("\nì‚¬ìš© ê°€ëŠ¥í•œ ë§¤í•‘ íŒŒì¼:")
        for i, json_file in enumerate(json_files, 1):
            relative_path = json_file.relative_to(results_dir)
            print(f"  {i}. {relative_path}")
        
        file_choice = input(f"\níŒŒì¼ ì„ íƒ (1-{len(json_files)}): ").strip()
        try:
            file_index = int(file_choice) - 1
            if 0 <= file_index < len(json_files):
                mapping_result = validate_and_fix_mappings(str(json_files[file_index]))
                if mapping_result:
                    create_quick_preview(mapping_result)
            else:
                print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")
        except ValueError:
            print("âŒ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    elif choice == "4":
        print("ğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return
    
    else:
        print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")


if __name__ == "__main__":
    main()
